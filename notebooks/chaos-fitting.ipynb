{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3104d30-0eeb-4a6e-bd19-919a0a9ac8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge  # For output layer training\n",
    "\n",
    "class EchoStateNetwork:\n",
    "    def __init__(self, n_reservoir=200, spectral_radius=0.9, input_scaling=1.0, leak_rate=0.3, ridge_alpha=1e-6):\n",
    "        self.n_reservoir = n_reservoir\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scaling = input_scaling\n",
    "        self.leak_rate = leak_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.W_in = None\n",
    "        self.W_res = None\n",
    "        self.W_out = None\n",
    "        self.x = None  # Reservoir state\n",
    "\n",
    "    def _initialize_weights(self, n_inputs=1):\n",
    "        # Input weights: random, scaled\n",
    "        self.W_in = np.random.uniform(-self.input_scaling, self.input_scaling, (self.n_reservoir, n_inputs))\n",
    "        \n",
    "        # Reservoir weights: random sparse, scaled to spectral radius\n",
    "        self.W_res = np.random.uniform(-0.5, 0.5, (self.n_reservoir, self.n_reservoir))\n",
    "        # Make sparse: keep 1% connections\n",
    "        sparsity = 0.01\n",
    "        n_connections = int(sparsity * self.n_reservoir**2)\n",
    "        indices = np.random.choice(self.n_reservoir**2, n_connections, replace=False)\n",
    "        self.W_res.flat[indices] = 0\n",
    "        # Scale to spectral radius\n",
    "        rho = np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
    "        self.W_res /= rho / self.spectral_radius if rho != 0 else 1\n",
    "\n",
    "    def _run_step(self, u):\n",
    "        if self.x is None:\n",
    "            self.x = np.zeros(self.n_reservoir)\n",
    "        self.x = (1 - self.leak_rate) * self.x + self.leak_rate * np.tanh(np.dot(self.W_res, self.x) + np.dot(self.W_in, u))\n",
    "        return self.x\n",
    "\n",
    "    def fit(self, u, y):\n",
    "        n_inputs = u.shape[1] if len(u.shape) > 1 else 1\n",
    "        self._initialize_weights(n_inputs)\n",
    "        \n",
    "        # Collect reservoir states\n",
    "        states = np.zeros((u.shape[0], self.n_reservoir))\n",
    "        for t in range(u.shape[0]):\n",
    "            states[t] = self._run_step(u[t])\n",
    "        \n",
    "        # Train output weights with Ridge regression (include bias)\n",
    "        states_with_bias = np.hstack([np.ones((u.shape[0], 1)), states])\n",
    "        self.W_out = Ridge(alpha=self.ridge_alpha).fit(states_with_bias, y).coef_.T\n",
    "\n",
    "    def predict(self, u):\n",
    "        predictions = []\n",
    "        self.x = np.zeros(self.n_reservoir)  # Reset state\n",
    "        for t in range(u.shape[0]):\n",
    "            state = self._run_step(u[t])\n",
    "            state_with_bias = np.hstack([1, state])\n",
    "            pred = np.dot(self.W_out.T, state_with_bias)[0]\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Function to generate Logistic Map data\n",
    "def logistic_map(x0, n_steps, r=4.0):\n",
    "    \"\"\"Logistic map: x_{n+1} = r * x_n * (1 - x_n)\"\"\"\n",
    "    x = np.zeros(n_steps)\n",
    "    x[0] = x0\n",
    "    for i in range(1, n_steps):\n",
    "        x[i] = r * x[i-1] * (1 - x[i-1])\n",
    "    return x\n",
    "\n",
    "# Generate data with transient\n",
    "total_steps = 3000\n",
    "transient_steps = 1000\n",
    "x0 = 0.1\n",
    "full_series = logistic_map(x0, total_steps)\n",
    "\n",
    "# Post-transient data\n",
    "post_transient_series = full_series[transient_steps:]\n",
    "\n",
    "# Prepare training data: input u = x_t, target y = x_{t+1}\n",
    "n_data = len(post_transient_series)\n",
    "train_u = post_transient_series[:-1].reshape(-1, 1)\n",
    "train_y = post_transient_series[1:].reshape(-1, 1)\n",
    "\n",
    "# Train ESN on all post-transient data\n",
    "esn = EchoStateNetwork(n_reservoir=100, spectral_radius=1.2, leak_rate=0.1, input_scaling=1.0)\n",
    "esn.fit(train_u, train_y)\n",
    "\n",
    "# Generate reproduction: feed original u to get predictions (mimic y)\n",
    "reproduced = esn.predict(train_u)\n",
    "\n",
    "# Plot comparison: original post-transient vs RC reproduction\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "t = np.arange(n_data - 1)\n",
    "ax.plot(t, post_transient_series[1:], label='Original Post-Transient', color='blue')\n",
    "ax.plot(t, reproduced.flatten(), label='RC Reproduction', color='red', linestyle='--', alpha=0.8)\n",
    "ax.set_title('Original Post-Transient Series vs. RC Reproduction')\n",
    "ax.set_xlabel('Time Steps')\n",
    "ax.set_ylabel('x')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute and print MSE for quantitative comparison\n",
    "mse = np.mean((post_transient_series[1:] - reproduced.flatten())**2)\n",
    "print(f'Mean Squared Error between Original and RC Reproduction: {mse:.6f}')\n",
    "\n",
    "# Use case:\n",
    "# 1. Run the code to generate logistic map data, discard first 1000 transient steps.\n",
    "# 2. Train RC on the post-transient data to mimic the map.\n",
    "# 3. Feed the input sequence back to RC to reproduce the sequence (forced mode).\n",
    "# 4. Plot compares the original target sequence with the RC output.\n",
    "# 5. Adjust n_reservoir, spectral_radius, etc., for better fitting.\n",
    "# 6. For other maps like Rulkov (2D), adapt to vector inputs/outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
